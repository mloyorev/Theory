{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNlMEDtXp6d60L26PE+TSwL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mloyorev/Theory/blob/main/8_InvestmentAdjustmentCostsNumba.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PTZzBOZynAPs",
        "outputId": "92a9a408-76f0-4179-b0b1-761773fabebc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting quantecon\n",
            "  Downloading quantecon-0.7.1-py3-none-any.whl (214 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m214.8/214.8 kB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numba>=0.49.0 in /usr/local/lib/python3.10/dist-packages (from quantecon) (0.58.1)\n",
            "Requirement already satisfied: numpy>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from quantecon) (1.23.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from quantecon) (2.31.0)\n",
            "Requirement already satisfied: scipy>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from quantecon) (1.11.4)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from quantecon) (1.12)\n",
            "Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba>=0.49.0->quantecon) (0.41.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->quantecon) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->quantecon) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->quantecon) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->quantecon) (2023.11.17)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->quantecon) (1.3.0)\n",
            "Installing collected packages: quantecon\n",
            "Successfully installed quantecon-0.7.1\n"
          ]
        }
      ],
      "source": [
        "!pip install quantecon"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import namedtuple\n",
        "import numpy as np\n",
        "import quantecon as qe\n",
        "from numba import njit, prange, int32\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "1uL1fjWMnGAU"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Once **again**, we use the functions:\n",
        "\n",
        "\n",
        "*   `argmax`\n",
        "*   `succesive approximation`\n",
        "\n"
      ],
      "metadata": {
        "id": "HZeQeAhQnWHe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@njit\n",
        "def argmax(list_object):\n",
        "    max_val = -np.inf\n",
        "    argmax_index = None\n",
        "    for i, x in enumerate(list_object):\n",
        "        if x > max_val:\n",
        "            max_val = x\n",
        "            argmax_index = i\n",
        "    return argmax_index"
      ],
      "metadata": {
        "id": "HyXwNXb5nM3x"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def successive_approx(T,\n",
        "                      x_0,\n",
        "                      tolerance=1e-6,\n",
        "                      max_iter=10_000,\n",
        "                      print_step=25,\n",
        "                      verbose=False):\n",
        "    x = x_0\n",
        "    error = tolerance + 1\n",
        "    k = 1\n",
        "    while error > tolerance and k <= max_iter:\n",
        "        x_new = T(x)\n",
        "        error = np.max(np.abs(x_new - x))\n",
        "        if verbose and k % print_step == 0:\n",
        "            print(f\"Completed iteration {k} with error {error}.\")\n",
        "        x = x_new\n",
        "        k += 1\n",
        "    if error > tolerance:\n",
        "        print(f\"Warning: Iteration hit upper bound {max_iter}.\")\n",
        "    elif verbose:\n",
        "        print(f\"Terminated successfully in {k} iterations.\")\n",
        "    return x"
      ],
      "metadata": {
        "id": "APTKLTSanQDw"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Investment with Adjustment Costs**\n",
        "\n",
        "We begin by assuming the case of a **monopolist facing an inverse demanda function** given by\n",
        "\n",
        "$$P_{t}=a_{0}-a_{1}Y_{t}+Z_{t}$$\n",
        "\n",
        "where\n",
        "\n",
        "\n",
        "*   $P_{t}$ is the price,\n",
        "*   $Y_{t}$ is the output,\n",
        "*   $a_{0}$ and $a_{1}$ are demand parameters, and\n",
        "*   $Z_{t}$ is the demand shock.\n",
        "\n",
        "The profits of the monopolist are represented by\n",
        "\n",
        "$$\\pi(Y_{t},Y_{t+1}, Z_{t})=(a_{0}-a_{1}Y_{t}+Z_{t})Y_{t}-\\gamma (Y_{t+1}-Y_{t})^{2}$$\n",
        "\n",
        "where the **investment adjustment cost** is given by the expression $\\gamma (Y_{t+1}-Y_{t})^{2}$. Notice that $\\gamma (Y_{t+1}-Y_{t})^{2}>0$ for any $t$.\n",
        "\n",
        "The ***monopolist seeks to maximize the expected discounted flow of benefits***, given the information available in period t.\n",
        "\n",
        "\\begin{align*}\n",
        "V(y_t, z_t) = \\max_{\\left\\{y_{t+1+\\tau}\\right\\}} E_t  \\sum_{\\tau=0}^{\\infty} \\beta^{\\tau} \\pi(y_{t+τ}, y_{t+1+τ}, z_{t+τ})\n",
        "\\end{align*}\n",
        "\n",
        "By assuming that the current demand shock is know, the value function can be expressed as\n",
        "\n",
        "$$V(y_t, y_t) =\\max_{\\left\\{y_{t+1}\\right\\}}E_{t}\\pi(y_{t},y_{t+1},z_{t})+ \\max_{\\left\\{y_{t+\\tau+1}\\right\\}} E_t  \\sum_{\\tau=1}^{\\infty} \\beta^{\\tau} \\pi(y_{t+τ}, y_{t+1+τ}, z_{t+τ})$$\n",
        "\n",
        "$$V(y_t, z_t) =\\max_{\\left\\{y_{t+1}\\right\\}}r(y_{t},y_{t+1},z_{t})+ \\max_{\\left\\{y_{t+\\tau+1}\\right\\}} E_t  \\sum_{\\tau=1}^{\\infty} \\beta^{\\tau} \\pi(y_{t+τ}, y_{t+1+τ}, z_{t+τ})$$\n",
        "\n",
        "By introducing the substitution $k+1=\\tau$ we obtain that\n",
        "\n",
        "$$V(Y_t, Z_t) =\\max_{\\left\\{Y_{t+1}\\right\\}}r(Y_{t},Y_{t+1},Z_{t})+ \\max_{\\left\\{Y_{t+k+2}\\right\\}} E_t  \\sum_{k=0}^{\\infty} \\beta^{k+1} \\pi(Y_{t+k+1}, Y_{t+k+2}, Z_{t+k+1})$$\n",
        "\n",
        "$$V(y_t, z_t) =\\max_{\\left\\{y_{t+1}\\right\\}}r(y_{t},y_{t+1},z_{t})+ \\max_{\\left\\{y_{t+k+2}\\right\\}}\\beta E_t  \\sum_{k=0}^{\\infty} \\beta^{k} \\pi(y_{t+k+1}, y_{t+k+2}, z_{t+k+1})$$\n",
        "\n",
        "According to the **law of iterated expectations**, the previous value function is equivalent to the following equation (we have already explain how this step works in `4_InventoryDynamics.ipynb` and `7_OptimalSavingsNumba.ipynb`)\n",
        "\n",
        "$$V(y_{t},z_{t})=\\max_{\\left\\{y_{t+1}\\right\\}}r(y_{t},y_{t+1},z_{t})+\\max_{\\left\\{y_{t+k+2}\\right\\}}\\beta \\int_{y_{t+1}}E_{t+1}\\sum_{k=0}^{\\infty} \\beta^{k} \\pi(y_{t+k+1}, y_{t+k+2}, z_{t+k+1})f(y_{t+1}|y_{t})dy_{t+1}$$\n",
        "\n",
        "$$V(y_{t},z_{t})=\\max_{\\left\\{y_{t+1}\\right\\}}r(y_{t},y_{t+1},z_{t})+\\beta\\int_{y_{t+1}}\\max_{\\left\\{y_{t+k+2}\\right\\}}E_{t+1}\\sum_{k=0}^{\\infty} \\beta^{k} \\pi(y_{t+k+1}, y_{t+k+2}, z_{t+k+1})f(y_{t+1}|y_{t})dy_{t+1}$$\n",
        "\n",
        "By the definition of the value function we have that\n",
        "\n",
        "$$V(y_{t},z_{t})=\\max_{\\left\\{y_{t+1}\\right\\}}r(y_{t},y_{t+1},z_{t})+\\beta\\int_{y_{t+1}}V(y_{t+1},z_{t+1})f(y_{t+1}|y_{t})dy_{t+1}$$\n",
        "\n",
        "$$V(y_{t},z_{t})=\\max_{\\left\\{y_{t+1}\\right\\}}r(y_{t},y_{t+1},z_{t})+\\beta E_{t}V(y_{t+1},z_{t+1})$$\n",
        "\n",
        "Therefore, the **Bellman equation** of the model is given by\n",
        "\n",
        "$$V(y,z)=\\max_{\\left\\{y'\\right\\}}r(y,y',z)+\\beta \\sum_{z'}V(y',z')Q(z',z)$$\n",
        "\n"
      ],
      "metadata": {
        "id": "ABbr5uRwnrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "One more time we use a `namedtuple` to store parameters and grids for the state space"
      ],
      "metadata": {
        "id": "_J7OzK7uVVCL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Model = namedtuple(\"Model\", (\"beta\",         # Discount factor\n",
        "                             \"a_0\", \"a_1\",   # Demand parameters\n",
        "                             \"gamma\",\"c\",    # Adjustment and unit cost, respectively\n",
        "                             \"y_size\",       # Grid size for the output\n",
        "                             \"z_size\",       # Grid size for the demand shock\n",
        "                             \"y_grid\",       # Output grid\n",
        "                             \"z_grid\",       # Demand shock grid\n",
        "                             \"Q\"))           # Transition matrix\n",
        "\n",
        "def create_investment_model(\n",
        "        r = 0.01,                                 # Interest rate\n",
        "        a_0 = 10.0, a_1 = 1.0,                    # Demand parameters\n",
        "        gamma = 25.0, c = 1.0,                    # Adjustment and unit cost\n",
        "        y_min = 0.0, y_max = 20.0, y_size = 100,  # Grid for output\n",
        "        rho = 0.9, nu = 1.0,                      # AR(1) parameters: rho is the persistence of the shock and gamma the volatility\n",
        "        z_size = 150):                            # Grid size for shock\n",
        "\n",
        "    beta = 1 / (1 + r)                                 # Calculate de discount factor\n",
        "    y_grid = np.linspace(y_min, y_max, y_size)         # It generates the output grid\n",
        "\n",
        "    mc = qe.tauchen(rho = rho, sigma = nu, n = z_size) # Computes a discretization of a Markov process\n",
        "    z_grid, Q = mc.state_values, mc.P                  # Gets the grid of states 'z' and the transition matrix Q\n",
        "\n",
        "    model = Model(beta = beta, a_0 = a_0, a_1 = a_1, gamma = gamma, c = c,\n",
        "                  y_size = y_size, z_size = z_size,\n",
        "                  y_grid = y_grid, z_grid = z_grid, Q = Q)\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "OVB6_ed7VQOt"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Then we compute the RHS of the Bellman equation."
      ],
      "metadata": {
        "id": "VqfnBVz-WLnU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@njit\n",
        "def B(i, j, ip, v, model):\n",
        "\n",
        "    β, a_0, a_1, γ, c, y_size, z_size, y_grid, z_grid, Q = model    # Unpacked model parameters\n",
        "    y, z, yp = y_grid[i], z_grid[j], y_grid[ip]                     # We use: - index i for the value of current production\n",
        "                                                                    #         - index j for the value of current demand shock\n",
        "                                                                    #         - index ip for the value of next period's production\n",
        "\n",
        "    r = (a_0 - a_1 * y + z - c) * y - γ * (yp - y)**2               # Calculates the revenues function\n",
        "\n",
        "    return r + β * np.dot(v[ip, :], Q[j, :])     # Dot product between the vector v[ip, :] and the row Q[j, :]"
      ],
      "metadata": {
        "id": "7IHGNI2LV9GY"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In order to solve this model, we have to prove that it satisifies the **Blackwell sufficiency conditions**"
      ],
      "metadata": {
        "id": "x1Zp12q2XO7t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **1. Monotonicity**\n",
        "\n",
        "Let $V,W$ two different functions that satisfies that $V(y,z)≤W(y,z)\n",
        "$ $∀y,z$. If we name $y',z'$ the output and the shock of the next period, resvectively, then...\n",
        "\n",
        "$$V(y',z')≤W(y',z'),  ∀y',z'$$\n",
        "\n",
        "If we multiply both sides of the inequality by the transition probability, then...\n",
        "\n",
        "$$V(y',z')Q(z,z')≤W(y',z')Q(z,z'),  ∀y',z'$$\n",
        "\n",
        "The inequality also holds for the expected value of value functions, such that...\n",
        "\n",
        "$$\\sum_{z'}V(y',z')Q(z,z')≤\\sum_{z'}W(y',z')Q(z,z')$$\n",
        "$$β\\sum_{z'}V(y',z')Q(z,z')≤β\\sum_{z'}W(y',z')Q(z,z')$$\n",
        "\n",
        "Finally we add both sides the maximization of the current benefits given a particular level of current output and shock, such that...\n",
        "\n",
        "$$\\max_{y'}r(y,z,y')+β\\sum_{z'}V(y',z')Q(z,z')≤\\max_{y'}r(y,z,y')+β\\sum_{z'}W(y',z')Q(z,z'),  ∀y,z$$\n",
        "\n",
        "Therefore, $T(V(y,z))≤T(W(y,z)), ∀y,z$, which means that ***the transformation satisifes monotonicity***.\n",
        "\n",
        "\n",
        "### **2. Discounting**\n",
        "\n",
        "Let's consider a value function $V$ and a positive constant $a$, such that...\n",
        "\n",
        "$$T(V(y,z)+a)=max_{y'}r(y,z,y')+β∑_{z'}(V(y',z')+a)Q(z,z')$$\n",
        "\n",
        "$$T(V(y,z)+a)=max_{y'}r(y,z,y')+β∑_{z'}(V(y',z'))Q(z,z')+β∑_{z'}aQ(z,z')$$\n",
        "\n",
        "$$T(V(y,z)+a)=max_{y'}r(y,z,y')+β∑_{z'}(V(y',z'))Q(z,z')+aβ∑_{z'}Q(z,z')$$\n",
        "\n",
        "it is fulfilled that $∑_{z'}Q(z,z')=1$, such that...\n",
        "\n",
        "$$T(V(y,z)+a)=max_{y'}r(y,z,y')+β∑_{z'}(V(y',z'))Q(z,z')+aβ$$\n",
        "\n",
        "$$T(V(y,z)+a)=T(V(y,z))+aβ$$\n",
        "\n",
        "Therefore, $T(V(y,z)+a)≤T(V(y,z))+aβ$, which means that the ***transformation satisfies discounting***.\n",
        "\n",
        "Therefore, ***since the transformation satisfies the Blackwell's sufficiency conditions***, then it has a unique solution."
      ],
      "metadata": {
        "id": "R7ib2uiZXZ4h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "As in `7_OptimalSavingsNumba.ipynb`, we are going to **use the following algorithms** to solve the model:\n",
        "\n",
        "\n",
        "\n",
        "*   Value Function Iteration (VFI).\n",
        "*   Howard Policy Iteration (HPI).\n",
        "*   Optimistic Policy Iteration (OPI).\n",
        "\n",
        "In order to be able to use this algorithms, we have to define the following operator.\n",
        "\n"
      ],
      "metadata": {
        "id": "1_G58yOuYkuz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# POLICY OPERATOR\n",
        "@njit(parallel=True)\n",
        "def T_sigma(v, sigma, model):\n",
        "    v_new = np.empty_like(v)\n",
        "    for i in prange(model.y_size):\n",
        "        for j in range(model.z_size):\n",
        "            v_new[i, j] = B(i, j, sigma[i, j], v, model)\n",
        "    return v_new\n",
        "\n",
        "# BELLMAN OPERATOR\n",
        "@njit(parallel=True)\n",
        "def T(v, model):\n",
        "    beta, a_0, a_1, gamma, c, y_size, z_size, y_grid, z_grid, Q = model\n",
        "    v_new = np.empty_like(v)\n",
        "    for i in prange(y_size):\n",
        "        for j in range(z_size):\n",
        "            v_new[i, j] = max([B(i, j, ip, v, model) for ip in range(y_size)])\n",
        "    return v_new\n",
        "\n",
        "# V-GREEDY POLICY\n",
        "@njit(parallel=True)\n",
        "def get_greedy(v, model):\n",
        "    beta, a_0, a_1, gamma, c, y_size, z_size, y_grid, z_grid, Q = model\n",
        "    sigma = np.empty_like(v, dtype=int32)\n",
        "    for i in prange(y_size):\n",
        "        for j in range(z_size):\n",
        "            sigma[i, j] = argmax([B(i, j, ip, v, model) for ip in range(y_size)])\n",
        "    return sigma\n",
        "\n",
        "# GET THE VALUE OF A POLICY\n",
        "@njit(parallel=True)\n",
        "def get_value(sigma, model):\n",
        "    # Unpack and set up\n",
        "    beta, a_0, a_1, gamma, c, y_size, z_size, y_grid, z_grid, Q = model\n",
        "    ny, nz = len(y_grid), len(z_grid)\n",
        "    n = ny * nz\n",
        "\n",
        "    # Initialize the transition matrix representing the probability of transition given σ.\n",
        "    P_sigma = np.zeros((ny, nz, ny, nz))\n",
        "\n",
        "    # Initialize the vector of rewards associated with each state given a policy σ.\n",
        "    r_sigma = np.zeros((ny, nz))\n",
        "\n",
        "    # For each combination of states, the value of the reward r_σ is calculated according to σ policy.\n",
        "    for i in range(ny):\n",
        "        for j in range(nz):\n",
        "            y, z, yp = y_grid[i], z_grid[j], y_grid[sigma[i, j]]\n",
        "            r_sigma[i, j] = (a_0 - a_1 * y + z - c) * y - gamma * (yp - y)**2\n",
        "\n",
        "    # If the state ip coincides with the state σ[i, j], the transition probability Q[j, jp] is assigned to the matrix P_σ for that state i, j.\n",
        "            for ip in range (ny):\n",
        "                for jp in range(nz):\n",
        "                    if ip == sigma[i, j]:\n",
        "                        P_sigma[i, j, ip, jp] = Q[j, jp]\n",
        "\n",
        "    # Reshape to standard matrix algebra form\n",
        "    r_sigma = r_sigma.reshape((n,))\n",
        "    P_sigma = P_sigma.reshape((n, n))\n",
        "\n",
        "    # Solve for the value of σ\n",
        "    I = np.identity(n)\n",
        "    v_sigma = np.linalg.solve(I - beta * P_sigma, r_sigma)\n",
        "\n",
        "    # Return as multi-index array\n",
        "    return np.reshape(v_sigma, (ny, nz))"
      ],
      "metadata": {
        "id": "vrC5ujfgXWUJ"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we are able to define the solvers of each algorithm."
      ],
      "metadata": {
        "id": "XtmAfRsuahsx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **1. Value Function Iteration (VFI)**\n",
        "\n",
        "We have already described the VFI algorithm in `2_NeoclasicalOptimalGrowthModel.ipynb`\n",
        "\n",
        "We introduce a function that implements the VFI algorithm."
      ],
      "metadata": {
        "id": "xcbeniJHanXX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def value_iteration(model, tol=1e-5):\n",
        "    vz = np.zeros((len(model.y_grid), len(model.z_grid)))\n",
        "    v_star = successive_approx(lambda v: T(v, model), vz, tolerance=tol)\n",
        "\n",
        "    return get_greedy(v_star, model)\n"
      ],
      "metadata": {
        "id": "yM2Obd4Ma-1c"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **2. Howard Policy Iteration (HPI)**\n",
        "\n",
        "We have already described the HPI algorithm in `7_OptimalSavingsNumba.ipynb`\n",
        "\n",
        "We introduce a function that implements the HPI algorithm."
      ],
      "metadata": {
        "id": "r4iJZMSvbEDy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def policy_iteration(model):\n",
        "    ny, nz = len(model.y_grid), len(model.z_grid)\n",
        "    sigma = np.ones((ny, nz), dtype=int)\n",
        "    i, error = 0, 1.0\n",
        "    while error > 0:\n",
        "        v_sigma = get_value(sigma, model)\n",
        "        sigma_new = get_greedy(v_sigma, model)\n",
        "        error = np.max(np.abs(sigma_new - sigma))\n",
        "        sigma = sigma_new\n",
        "        i = i + 1\n",
        "        print(f\"Concluded loop {i} with error {error}.\")\n",
        "\n",
        "    return sigma"
      ],
      "metadata": {
        "id": "qkb4arlpbScB"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **3. Optimistic Policy Iteration (OPI)**\n",
        "\n",
        "We have already described the OPI algorithm in `7_OptimalSavingsNumba.ipynb`\n",
        "\n",
        "We introduce a function that implements the OPI algorithm."
      ],
      "metadata": {
        "id": "LwhzpHV2btwv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def optimistic_policy_iteration(model, tol=1e-5, m=100):\n",
        "    v = np.zeros((len(model.y_grid), len(model.z_grid)))\n",
        "    error = tol + 1\n",
        "\n",
        "    while error > tol:\n",
        "        last_v = v\n",
        "        sigma = get_greedy(v, model)\n",
        "        for _ in range(m):\n",
        "            v = T_sigma(v, sigma, model)\n",
        "        error = np.max(np.abs(v - last_v))\n",
        "\n",
        "    return get_greedy(v, model)"
      ],
      "metadata": {
        "id": "uaR2xp4WbtNe"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we can test this algorithms"
      ],
      "metadata": {
        "id": "I_Z5BveddJAJ"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4ID7sb0FdMWO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}